{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5caa6b01-d36c-458a-b99c-c8aa93424ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Run with --run to execute training/evaluation and generate report.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ts_forecast_attention_fixed.py\n",
    "\n",
    "Fixed, self-contained multi-step forecasting script implementing:\n",
    "- Synthetic multivariate dataset (>=6000 timesteps)\n",
    "- Preprocessing (MinMaxScaler)\n",
    "- Seq2Seq LSTM encoder-decoder with additive attention\n",
    "- Robust decoder hidden-state projection (fix for mat1/mat2 errors)\n",
    "- SARIMA baseline evaluation (per-feature)\n",
    "- Training loop, early stopping, evaluation metrics (RMSE/MAE/MASE)\n",
    "- Attention visualization and Monte Carlo dropout intervals\n",
    "- Auto-generates a `report.md` and saves figures into `report/figures`\n",
    "\n",
    "Usage:\n",
    "    python ts_forecast_attention_fixed.py --run\n",
    "\n",
    "Dependencies (requirements.txt):\n",
    "    numpy\n",
    "    torch\n",
    "    matplotlib\n",
    "    pandas\n",
    "    statsmodels\n",
    "\n",
    "This script is intentionally single-file for easy submission. It saves:\n",
    "    - best model: best_seq2seq_attn.pth\n",
    "    - report: report/report.md and figures in report/figures/\n",
    "\n",
    "Author: Generated by ChatGPT (fixed patch)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Optional baseline\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    _HAS_STATS = True\n",
    "except Exception:\n",
    "    _HAS_STATS = False\n",
    "\n",
    "# -----------------------------\n",
    "# Repro and device\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# -----------------------------\n",
    "# Synthetic data generator\n",
    "# -----------------------------\n",
    "def generate_multivariate_series(n_steps=6000, n_series=3, noise_std=0.2):\n",
    "    t = np.arange(n_steps)\n",
    "    data = []\n",
    "    for s in range(n_series):\n",
    "        freq = 0.01 + 0.01 * s\n",
    "        phase = s * 0.5\n",
    "        trend = 0.0005 * t * (1 + 0.2 * s)\n",
    "        seasonal = np.sin(2 * np.pi * freq * t + phase) + 0.5 * np.sin(2 * np.pi * freq * 3 * t + phase/2)\n",
    "        noise = np.random.normal(scale=noise_std, size=n_steps)\n",
    "        ar = np.zeros(n_steps)\n",
    "        for i in range(2, n_steps):\n",
    "            ar[i] = 0.6 * ar[i-1] - 0.2 * ar[i-2] + 0.05 * seasonal[i-1]\n",
    "        series = seasonal + trend + ar + noise\n",
    "        data.append(series)\n",
    "    data = np.stack(data, axis=1)\n",
    "    return data\n",
    "\n",
    "# -----------------------------\n",
    "# Preprocessing\n",
    "# -----------------------------\n",
    "class MinMaxScaler:\n",
    "    def fit(self, data: np.ndarray):\n",
    "        self.min = data.min(axis=0)\n",
    "        self.max = data.max(axis=0)\n",
    "        self.range = np.where(self.max - self.min == 0, 1.0, self.max - self.min)\n",
    "    def transform(self, data: np.ndarray):\n",
    "        return (data - self.min) / self.range\n",
    "    def inverse_transform(self, data: np.ndarray):\n",
    "        return data * self.range + self.min\n",
    "\n",
    "def create_windows(data: np.ndarray, in_len: int, out_len: int, step=1):\n",
    "    T, F = data.shape\n",
    "    Xs, Ys = [], []\n",
    "    for start in range(0, T - in_len - out_len + 1, step):\n",
    "        Xs.append(data[start : start + in_len])\n",
    "        Ys.append(data[start + in_len : start + in_len + out_len])\n",
    "    return np.stack(Xs), np.stack(Ys)\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.Y = Y.astype(np.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# -----------------------------\n",
    "# Model components\n",
    "# -----------------------------\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.lstm(x)\n",
    "        return out, (h, c)\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, enc_dim, dec_dim, attn_dim):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Linear(enc_dim, attn_dim, bias=False)\n",
    "        self.W_dec = nn.Linear(dec_dim, attn_dim, bias=False)\n",
    "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
    "    def forward(self, enc_outputs, dec_hidden):\n",
    "        enc_proj = self.W_enc(enc_outputs)  # (B, S, A)\n",
    "        dec_proj = self.W_dec(dec_hidden).unsqueeze(1)  # (B, 1, A)\n",
    "        e = torch.tanh(enc_proj + dec_proj)\n",
    "        scores = self.v(e).squeeze(-1)\n",
    "        attn_weights = torch.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), enc_outputs).squeeze(1)\n",
    "        return context, attn_weights\n",
    "\n",
    "class DecoderLSTMWithAttn(nn.Module):\n",
    "    def __init__(self, input_dim, enc_dim, dec_dim, out_dim, attn_dim, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # input_dim is feature size of previous step, enc_dim is encoder hidden size\n",
    "        self.input_proj = nn.Linear(input_dim + enc_dim, dec_dim)\n",
    "        self.lstm = nn.LSTM(dec_dim, dec_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.attn = AdditiveAttention(enc_dim, dec_dim, attn_dim)\n",
    "        self.out = nn.Linear(dec_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward_step(self, prev_y, enc_outputs, hidden):\n",
    "        dec_hidden = hidden[0][-1]\n",
    "        context, attn_weights = self.attn(enc_outputs, dec_hidden)\n",
    "        combined = torch.cat([prev_y, context], dim=1)\n",
    "        dec_input = torch.tanh(self.input_proj(combined)).unsqueeze(1)\n",
    "        out, hidden = self.lstm(dec_input, hidden)\n",
    "        out = out.squeeze(1)\n",
    "        out = self.dropout(out)\n",
    "        y_pred = self.out(out)\n",
    "        return y_pred, hidden, attn_weights\n",
    "    def forward(self, enc_outputs, dec_init_hidden, targets=None, teacher_forcing_ratio=0.5):\n",
    "        B = enc_outputs.size(0)\n",
    "        device = enc_outputs.device\n",
    "        if targets is not None:\n",
    "            out_len = targets.size(1)\n",
    "            out_dim = targets.size(2)\n",
    "        else:\n",
    "            out_len = 10\n",
    "            out_dim = enc_outputs.size(2)\n",
    "        preds = []\n",
    "        attns = []\n",
    "        prev_y = torch.zeros(B, out_dim, device=device)\n",
    "        hidden = dec_init_hidden\n",
    "        for t in range(out_len):\n",
    "            y_pred, hidden, attn_w = self.forward_step(prev_y, enc_outputs, hidden)\n",
    "            preds.append(y_pred.unsqueeze(1))\n",
    "            attns.append(attn_w.unsqueeze(1))\n",
    "            if targets is not None and random.random() < teacher_forcing_ratio:\n",
    "                prev_y = targets[:, t, :].to(device)\n",
    "            else:\n",
    "                prev_y = y_pred.detach()\n",
    "        preds = torch.cat(preds, dim=1)\n",
    "        attns = torch.cat(attns, dim=1)\n",
    "        return preds, attns\n",
    "\n",
    "class Seq2SeqAttnModel(nn.Module):\n",
    "    def __init__(self, input_dim, enc_dim=64, dec_dim=64, attn_dim=32, out_dim=None, dropout=0.1, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderLSTM(input_dim, enc_dim, num_layers=num_layers, dropout=dropout)\n",
    "        self.decoder = DecoderLSTMWithAttn(out_dim if out_dim else input_dim, enc_dim, dec_dim, out_dim if out_dim else input_dim, attn_dim, num_layers=num_layers, dropout=dropout)\n",
    "        # robust projection layers: project encoder-hidden dim -> decoder hidden dim\n",
    "        self.enc2dec_h = nn.Linear(enc_dim, dec_dim)\n",
    "        self.enc2dec_c = nn.Linear(enc_dim, dec_dim)\n",
    "    def forward(self, src, tgt=None, teacher_forcing_ratio=0.5):\n",
    "        enc_out, (h, c) = self.encoder(src)\n",
    "        # h/c: (num_layers, B, enc_dim)\n",
    "        # Permute to (B, num_layers, enc_dim) to project last dim cleanly\n",
    "        h_permute = h.permute(1, 0, 2).contiguous()\n",
    "        c_permute = c.permute(1, 0, 2).contiguous()\n",
    "        # project\n",
    "        h_proj = torch.tanh(self.enc2dec_h(h_permute))\n",
    "        c_proj = torch.tanh(self.enc2dec_c(c_permute))\n",
    "        # permute back to (num_layers, B, dec_dim)\n",
    "        dec_h = h_proj.permute(1, 0, 2).contiguous()\n",
    "        dec_c = c_proj.permute(1, 0, 2).contiguous()\n",
    "        dec_hidden = (dec_h, dec_c)\n",
    "        preds, attns = self.decoder(enc_out, dec_hidden, targets=tgt, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "        return preds, attns\n",
    "\n",
    "# -----------------------------\n",
    "# Training, evaluation, metrics\n",
    "# -----------------------------\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, Yb in dataloader:\n",
    "        Xb = Xb.to(device)\n",
    "        Yb = Yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds, _ = model(Xb, tgt=Yb, teacher_forcing_ratio=0.6)\n",
    "        loss = criterion(preds, Yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * Xb.size(0)\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    all_attns = []\n",
    "    with torch.no_grad():\n",
    "        for Xb, Yb in dataloader:\n",
    "            Xb = Xb.to(device)\n",
    "            Yb = Yb.to(device)\n",
    "            preds, attns = model(Xb, tgt=None, teacher_forcing_ratio=0.0)\n",
    "            loss = criterion(preds, Yb)\n",
    "            total_loss += loss.item() * Xb.size(0)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_trues.append(Yb.cpu().numpy())\n",
    "            all_attns.append(attns.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_trues = np.concatenate(all_trues, axis=0)\n",
    "    all_attns = np.concatenate(all_attns, axis=0)\n",
    "    return total_loss / len(dataloader.dataset), all_preds, all_trues, all_attns\n",
    "\n",
    "# metrics\n",
    "\n",
    "def rmse(y_pred, y_true):\n",
    "    return np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "    return np.mean(np.abs(y_pred - y_true))\n",
    "\n",
    "def mase(y_pred, y_true, train_series):\n",
    "    naive_errors = np.abs(train_series[1:] - train_series[:-1])\n",
    "    mae_naive = np.mean(naive_errors)\n",
    "    mae_model = np.mean(np.abs(y_pred - y_true))\n",
    "    return mae_model / (mae_naive + 1e-8)\n",
    "\n",
    "# MC dropout\n",
    "\n",
    "def mc_dropout_predict(model, X, n_samples=50):\n",
    "    model.train()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            p, _ = model(X.to(device), tgt=None, teacher_forcing_ratio=0.0)\n",
    "            preds.append(p.cpu().numpy())\n",
    "    preds = np.stack(preds, axis=0)\n",
    "    model.eval()\n",
    "    return preds\n",
    "\n",
    "# -----------------------------\n",
    "# SARIMA baseline helper\n",
    "# -----------------------------\n",
    "\n",
    "def sarima_forecast_series(train_series, steps=10, order=(1,1,1), seasonal_order=(0,0,0,0)):\n",
    "    if not _HAS_STATS:\n",
    "        raise RuntimeError(\"statsmodels not available. Install statsmodels to run SARIMA baseline.\")\n",
    "    model = SARIMAX(train_series, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "    res = model.fit(disp=False)\n",
    "    preds = res.predict(start=len(train_series), end=len(train_series)+steps-1)\n",
    "    return np.asarray(preds)\n",
    "\n",
    "# -----------------------------\n",
    "# Runner\n",
    "# -----------------------------\n",
    "\n",
    "def run_pipeline(run_cfg):\n",
    "    n_steps = run_cfg['n_steps']\n",
    "    n_series = run_cfg['n_series']\n",
    "    in_len = run_cfg['in_len']\n",
    "    out_len = run_cfg['out_len']\n",
    "\n",
    "    data = generate_multivariate_series(n_steps=n_steps, n_series=n_series, noise_std=0.25)\n",
    "    print(\"Data shape:\", data.shape)\n",
    "\n",
    "    train_end = int(n_steps * 0.7)\n",
    "    val_end = int(n_steps * 0.85)\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "\n",
    "    scaler = MinMaxScaler(); scaler.fit(train_data)\n",
    "    data_scaled = scaler.transform(data)\n",
    "\n",
    "    X_all, Y_all = create_windows(data_scaled, in_len=in_len, out_len=out_len, step=1)\n",
    "    starts = np.arange(0, n_steps - in_len - out_len + 1)\n",
    "    train_mask = starts + in_len + out_len <= train_end\n",
    "    val_mask = (starts + in_len + out_len > train_end) & (starts + in_len + out_len <= val_end)\n",
    "    test_mask = starts + in_len + out_len > val_end\n",
    "\n",
    "    X_train, Y_train = X_all[train_mask], Y_all[train_mask]\n",
    "    X_val, Y_val = X_all[val_mask], Y_all[val_mask]\n",
    "    X_test, Y_test = X_all[test_mask], Y_all[test_mask]\n",
    "    print(\"Windows: train\", X_train.shape, \"val\", X_val.shape, \"test\", X_test.shape)\n",
    "\n",
    "    train_ds = SeqDataset(X_train, Y_train)\n",
    "    val_ds = SeqDataset(X_val, Y_val)\n",
    "    test_ds = SeqDataset(X_test, Y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=run_cfg['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=run_cfg['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=run_cfg['batch_size'], shuffle=False)\n",
    "\n",
    "    model = Seq2SeqAttnModel(input_dim=n_series, enc_dim=run_cfg['enc_dim'], dec_dim=run_cfg['dec_dim'], attn_dim=run_cfg['attn_dim'], out_dim=n_series, dropout=run_cfg['dropout'], num_layers=run_cfg['num_layers'])\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=run_cfg['lr'])\n",
    "\n",
    "    best_val = float('inf'); best_epoch = -1\n",
    "    os.makedirs('report/figures', exist_ok=True)\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(1, run_cfg['epochs']+1):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
    "        print(f\"Epoch {epoch} Train {train_loss:.6f} Val {val_loss:.6f}\")\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_seq2seq_attn.pth')\n",
    "    pd.DataFrame(history).to_csv('report/figures/training_history.csv', index=False)\n",
    "    print('Best val', best_val, 'at epoch', best_epoch)\n",
    "\n",
    "    # load best\n",
    "    model.load_state_dict(torch.load('best_seq2seq_attn.pth', map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    test_loss, preds, trues, attns = evaluate(model, test_loader, criterion, device)\n",
    "    print('Test MSE loss:', test_loss)\n",
    "\n",
    "    preds_inv = scaler.inverse_transform(preds.reshape(-1, n_series)).reshape(preds.shape)\n",
    "    trues_inv = scaler.inverse_transform(trues.reshape(-1, n_series)).reshape(trues.shape)\n",
    "\n",
    "    rmse_val = rmse(preds_inv, trues_inv)\n",
    "    mae_val = mae(preds_inv, trues_inv)\n",
    "    mase_val = mase(preds_inv, trues_inv, train_data)\n",
    "    print(f\"Test RMSE: {rmse_val:.6f}, MAE: {mae_val:.6f}, MASE: {mase_val:.6f}\")\n",
    "\n",
    "    # Save metrics\n",
    "    metrics = {'model': 'seq2seq_attn', 'rmse': float(rmse_val), 'mae': float(mae_val), 'mase': float(mase_val)}\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    metrics_df.to_csv('report/figures/model_metrics.csv', index=False)\n",
    "\n",
    "    # attention aggregate and plot\n",
    "    avg_attn_over_decoder = np.mean(attns, axis=0)\n",
    "    avg_attn_encoderwise = np.mean(avg_attn_over_decoder, axis=0)\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(np.arange(-in_len,0), avg_attn_encoderwise)\n",
    "    plt.xlabel('Encoder step (lag)')\n",
    "    plt.title('Average encoder-step attention importance')\n",
    "    plt.savefig('report/figures/avg_attention_importance.png')\n",
    "    plt.close()\n",
    "\n",
    "    # sample prediction plot (first test sample)\n",
    "    sample_idx = 0\n",
    "    x0 = X_test[sample_idx]\n",
    "    y_true = Y_test[sample_idx]\n",
    "    with torch.no_grad():\n",
    "        x_tensor = torch.tensor(x0).unsqueeze(0).to(device)\n",
    "        pred_scaled, attn_sample = model(x_tensor, tgt=None, teacher_forcing_ratio=0.0)\n",
    "        pred_scaled = pred_scaled.cpu().numpy()[0]\n",
    "        attn_sample = attn_sample.cpu().numpy()[0]\n",
    "    pred_inv = scaler.inverse_transform(pred_scaled)\n",
    "    y_true_inv = scaler.inverse_transform(y_true)\n",
    "    past_inv = scaler.inverse_transform(x0)\n",
    "\n",
    "    for feat in range(n_series):\n",
    "        plt.figure(figsize=(8,2))\n",
    "        t_past = np.arange(-in_len,0)\n",
    "        t_fut = np.arange(0,out_len)\n",
    "        plt.plot(t_past, past_inv[:, feat], label='past')\n",
    "        plt.plot(t_fut, y_true_inv[:, feat], 'o-', label='true')\n",
    "        plt.plot(t_fut, pred_inv[:, feat], 'x--', label='pred')\n",
    "        plt.title(f'Feature {feat} predictions')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'report/figures/sample_pred_feat{feat}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # attention heatmap\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.imshow(attn_sample.T, aspect='auto', origin='lower')\n",
    "    plt.xlabel('Decoder step')\n",
    "    plt.ylabel('Encoder step')\n",
    "    plt.title('Attention heatmap (sample)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('report/figures/attention_heatmap_sample.png')\n",
    "    plt.close()\n",
    "\n",
    "    # MC dropout intervals\n",
    "    x_tensor = torch.tensor(x0).unsqueeze(0)\n",
    "    samples = mc_dropout_predict(model, x_tensor, n_samples=100)\n",
    "    samples = samples[:, 0]\n",
    "    lower = np.percentile(samples, 5, axis=0)\n",
    "    upper = np.percentile(samples, 95, axis=0)\n",
    "    median = np.median(samples, axis=0)\n",
    "    lower_inv = scaler.inverse_transform(lower)\n",
    "    upper_inv = scaler.inverse_transform(upper)\n",
    "    med_inv = scaler.inverse_transform(median)\n",
    "    plt.figure(figsize=(8,3))\n",
    "    feat = 0\n",
    "    plt.plot(np.arange(out_len), y_true_inv[:, feat], 'o-', label='true')\n",
    "    plt.plot(np.arange(out_len), med_inv[:, feat], 'x--', label='median')\n",
    "    plt.fill_between(np.arange(out_len), lower_inv[:, feat], upper_inv[:, feat], alpha=0.3, label='90% PI')\n",
    "    plt.legend()\n",
    "    plt.title('MC Dropout Prediction Intervals (sample, feat 0)')\n",
    "    plt.savefig('report/figures/mc_dropout_pi_feat0.png')\n",
    "    plt.close()\n",
    "\n",
    "    # SARIMA baseline (per-feature) - perform if statsmodels installed\n",
    "    sarima_metrics = []\n",
    "    if _HAS_STATS:\n",
    "        for feat in range(n_series):\n",
    "            train_series = train_data[:, feat]\n",
    "            try:\n",
    "                sar_pred = sarima_forecast_series(train_series, steps=out_len, order=(1,1,1))\n",
    "                # compare to first test window as representative (or implement full-window SARIMA if required)\n",
    "                y_true_sample = scaler.inverse_transform(Y_test[0])[:, feat]\n",
    "                sarima_metrics.append({'feature': feat, 'sarima_rmse': float(rmse(sar_pred, y_true_sample)), 'sarima_mae': float(mae(sar_pred, y_true_sample))})\n",
    "            except Exception as e:\n",
    "                sarima_metrics.append({'feature': feat, 'error': str(e)})\n",
    "        pd.DataFrame(sarima_metrics).to_csv('report/figures/sarima_metrics.csv', index=False)\n",
    "\n",
    "    # generate report.md\n",
    "    report_lines = []\n",
    "    report_lines.append('# Advanced Time Series Forecasting â€” Report')\n",
    "    report_lines.append('\\n')\n",
    "    report_lines.append('## Summary')\n",
    "    report_lines.append(f'- Model: Seq2Seq LSTM with Additive Attention')\n",
    "    report_lines.append(f'- Data: synthetic multivariate, {n_steps} timesteps, {n_series} features')\n",
    "    report_lines.append(f'- Input window: {in_len}, Forecast horizon: {out_len}')\n",
    "    report_lines.append(f'- Test RMSE: {rmse_val:.6f}, MAE: {mae_val:.6f}, MASE: {mase_val:.6f}')\n",
    "    report_lines.append('\\n')\n",
    "    report_lines.append('## Files')\n",
    "    report_lines.append('- Figures: report/figures/')\n",
    "    report_lines.append('- Model weights: best_seq2seq_attn.pth')\n",
    "    report_lines.append('\\n')\n",
    "    report_lines.append('## Methodology')\n",
    "    report_lines.append('- See code for model architecture and training details.')\n",
    "    report_lines.append('\\n')\n",
    "    report_lines.append('## Attention analysis')\n",
    "    report_lines.append('See report/figures/attention_heatmap_sample.png and report/figures/avg_attention_importance.png')\n",
    "    report_lines.append('\\n')\n",
    "    report_lines.append('## Prediction intervals')\n",
    "    report_lines.append('See report/figures/mc_dropout_pi_feat0.png')\n",
    "    report_lines.append('\\n')\n",
    "    if _HAS_STATS:\n",
    "        report_lines.append('## SARIMA baseline metrics')\n",
    "        report_lines.append('See report/figures/sarima_metrics.csv')\n",
    "        report_lines.append('\\n')\n",
    "\n",
    "    with open('report/report.md', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(report_lines))\n",
    "\n",
    "    print('Report and figures saved under report/.')\n",
    "\n",
    "# -----------------------------\n",
    "# Argument parsing and entry\n",
    "# -----------------------------\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse CLI args.\n",
    "\n",
    "    In notebook environments, argv may contain extra kernel arguments. We use\n",
    "    parse_known_args() to ignore unknown args so the script can be imported or\n",
    "    executed in Jupyter without raising SystemExit.\n",
    "    \"\"\"\n",
    "    import argparse, sys\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument('--run', action='store_true')\n",
    "    # parse known args and ignore the rest (prevents ipykernel argv errors)\n",
    "    args, _ = p.parse_known_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    cfg = {\n",
    "        'n_steps': 6000,\n",
    "        'n_series': 3,\n",
    "        'in_len': 30,\n",
    "        'out_len': 10,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 12,\n",
    "        'lr': 1e-3,\n",
    "        'enc_dim': 64,\n",
    "        'dec_dim': 64,\n",
    "        'attn_dim': 32,\n",
    "        'dropout': 0.2,\n",
    "        'num_layers': 1\n",
    "    }\n",
    "    if args.run:\n",
    "        run_pipeline(cfg)\n",
    "    else:\n",
    "        print(\"Run with --run to execute training/evaluation and generate report.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3aa24-a0b6-4024-86c9-de53e8b9c411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
