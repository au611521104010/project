{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3571173-b0b2-48d9-9429-9c38429403fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Generated data shape: (7000, 4)\n",
      "Splits -> train_end: 4900 val_end: 5950\n",
      "Dataset sizes (samples): 4795 1041 1041\n",
      "Model params: 369033\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "time_series_attention_project_fixed.py\n",
    "\n",
    "Fixed full pipeline:\n",
    "- Synthetic multivariate dataset generation (>=5000 rows)\n",
    "- Preprocessing: train/val/test split, scalers, sliding windows\n",
    "- Seq2Seq LSTM with Bahdanau Attention predicting next N steps\n",
    "- Training loop with checkpointing\n",
    "- Evaluation: RMSE, MAE, MASE\n",
    "- Monte Carlo dropout prediction intervals\n",
    "- Attention visualization\n",
    "- Baseline SARIMAX example (single-var)\n",
    "\n",
    "Notes:\n",
    "- This version removes the `verbose` arg from ReduceLROnPlateau (older PyTorch compatibility).\n",
    "- Decoder corrected: no dynamic layers inside forward; teacher forcing implemented correctly.\n",
    "- Ensure required packages installed: numpy pandas matplotlib scikit-learn torch statsmodels tqdm\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ---------------- 1) Synthetic data generation ----------------\n",
    "def generate_multivariate_series(n_steps=7000, n_vars=4, noise_std=0.2, seasonal_periods=[24,168]):\n",
    "    t = np.arange(n_steps).astype(float)\n",
    "    data = np.zeros((n_steps, n_vars), dtype=float)\n",
    "\n",
    "    # var0: trend + multiple seasonalities\n",
    "    data[:,0] = 0.01*t + 2.0*np.sin(2*np.pi*t/seasonal_periods[0]) \\\n",
    "                + 0.5*np.sin(2*np.pi*t/seasonal_periods[1]) \\\n",
    "                + 0.2*np.sin(2*np.pi*t/7.0)\n",
    "\n",
    "    # var1: nonlinear function of var0 + additional seasonality\n",
    "    data[:,1] = 0.5*np.log1p(np.abs(data[:,0])) * np.sign(data[:,0]) + 0.3*np.cos(2*np.pi*t/12.0)\n",
    "\n",
    "    # var2: slow trend + spikes\n",
    "    data[:,2] = 0.005*t + 0.3*np.sin(2*np.pi*t/30.0)\n",
    "    spikes = (np.random.rand(n_steps) < 0.002).astype(float)\n",
    "    data[:,2] += spikes * (np.random.randn(n_steps)*5.0)\n",
    "\n",
    "    # var3: random walk + seasonal forcing\n",
    "    rw = np.cumsum(0.01*np.random.randn(n_steps))\n",
    "    data[:,3] = rw + 0.4*np.sin(2*np.pi*t/(seasonal_periods[0]*0.5))\n",
    "\n",
    "    # cross-coupling and noise\n",
    "    data[:,0] += 0.2*data[:,3]\n",
    "    data[:,1] += 0.1*data[:,2]\n",
    "    data += noise_std * np.random.randn(*data.shape)\n",
    "\n",
    "    return pd.DataFrame(data, columns=[f\"var{i}\" for i in range(n_vars)])\n",
    "\n",
    "# Generate\n",
    "n_steps = 7000\n",
    "df = generate_multivariate_series(n_steps=n_steps, n_vars=4, noise_std=0.3)\n",
    "print(\"Generated data shape:\", df.shape)\n",
    "\n",
    "# ---------------- 2) Preprocessing / Sliding windows ----------------\n",
    "INPUT_LEN = 96\n",
    "PRED_LEN = 10\n",
    "FEATURES = df.columns.tolist()\n",
    "OUTPUT_SIZE = len(FEATURES)\n",
    "\n",
    "# splits\n",
    "train_frac, val_frac = 0.7, 0.15\n",
    "train_end = int(len(df) * train_frac)\n",
    "val_end = int(len(df) * (train_frac + val_frac))\n",
    "print(\"Splits -> train_end:\", train_end, \"val_end:\", val_end)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.iloc[:train_end].values)  # fit only on train\n",
    "scaled = scaler.transform(df.values)\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data_array, input_len, pred_len, start_idx, end_idx):\n",
    "        self.data = data_array\n",
    "        self.input_len = input_len\n",
    "        self.pred_len = pred_len\n",
    "        self.start = start_idx\n",
    "        self.end = end_idx\n",
    "        self.starts = []\n",
    "        for i in range(self.start, self.end - self.input_len - self.pred_len + 1):\n",
    "            self.starts.append(i)\n",
    "    def __len__(self):\n",
    "        return len(self.starts)\n",
    "    def __getitem__(self, idx):\n",
    "        i = self.starts[idx]\n",
    "        x = self.data[i:i+self.input_len]\n",
    "        y = self.data[i+self.input_len:i+self.input_len+self.pred_len]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "train_ds = SeqDataset(scaled, INPUT_LEN, PRED_LEN, 0, train_end)\n",
    "val_ds   = SeqDataset(scaled, INPUT_LEN, PRED_LEN, train_end-INPUT_LEN, val_end)\n",
    "test_ds  = SeqDataset(scaled, INPUT_LEN, PRED_LEN, val_end-INPUT_LEN, len(df))\n",
    "\n",
    "BATCH = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "print(\"Dataset sizes (samples):\", len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "# ---------------- 3) Model: Encoder / Attention / Decoder ----------------\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        outputs, (h, c) = self.lstm(x)  # outputs: (B, T, H)\n",
    "        return outputs, (h, c)\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, enc_hidden, dec_hidden):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(enc_hidden, dec_hidden)\n",
    "        self.W2 = nn.Linear(dec_hidden, dec_hidden)\n",
    "        self.V  = nn.Linear(dec_hidden, 1)\n",
    "    def forward(self, enc_outputs, dec_hidden):\n",
    "        # enc_outputs: (B, T_enc, H_enc)\n",
    "        # dec_hidden: (B, H_dec)\n",
    "        dec_expanded = dec_hidden.unsqueeze(1).repeat(1, enc_outputs.size(1), 1)  # (B, T_enc, H_dec)\n",
    "        score = self.V(torch.tanh(self.W1(enc_outputs) + self.W2(dec_expanded)))  # (B, T_enc, 1)\n",
    "        attn_weights = torch.softmax(score, dim=1)  # (B, T_enc, 1)\n",
    "        context = torch.sum(attn_weights * enc_outputs, dim=1)  # (B, H_enc)\n",
    "        return context, attn_weights.squeeze(-1)  # (B, T_enc)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size, enc_hidden_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        # Using LSTMCell for autoregressive decoding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTMCell(output_size + enc_hidden_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(enc_hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # projection from encoder hidden to initial decoder hidden if dimensions differ\n",
    "        if enc_hidden_size != hidden_size:\n",
    "            self.enc2dec = nn.Linear(enc_hidden_size, hidden_size)\n",
    "        else:\n",
    "            self.enc2dec = None\n",
    "        # projection from encoder last output to initial \"previous output\" (so shapes align)\n",
    "        if enc_hidden_size != output_size:\n",
    "            self.enc2out = nn.Linear(enc_hidden_size, output_size)\n",
    "        else:\n",
    "            self.enc2out = None\n",
    "\n",
    "    def forward(self, enc_outputs, y_prev=None, pred_len=10, teacher_forcing_rate=0.5):\n",
    "        \"\"\"\n",
    "        enc_outputs: (B, T_enc, H_enc)\n",
    "        y_prev: (B, pred_len, output_size) scaled targets for teacher forcing (optional)\n",
    "        \"\"\"\n",
    "        B = enc_outputs.size(0)\n",
    "        T_enc = enc_outputs.size(1)\n",
    "        device = enc_outputs.device\n",
    "\n",
    "        # initialize decoder hidden state from mean of enc outputs (projected if needed)\n",
    "        enc_mean = torch.mean(enc_outputs, dim=1)  # (B, H_enc)\n",
    "        if self.enc2dec is not None:\n",
    "            hx = torch.tanh(self.enc2dec(enc_mean))\n",
    "        else:\n",
    "            hx = torch.tanh(enc_mean)\n",
    "        cx = torch.zeros(B, self.hidden_size, device=device)\n",
    "\n",
    "        # initial prev_out: map last encoder step to output_size, or zero\n",
    "        last_enc = enc_outputs[:, -1, :]  # (B, H_enc)\n",
    "        if self.enc2out is not None:\n",
    "            prev_out = torch.tanh(self.enc2out(last_enc))\n",
    "        else:\n",
    "            # shapes match only when enc_hidden == output_size; else use zeros\n",
    "            if last_enc.size(1) == self.fc.out_features:\n",
    "                prev_out = last_enc\n",
    "            else:\n",
    "                prev_out = torch.zeros(B, self.fc.out_features, device=device)\n",
    "\n",
    "        outputs = []\n",
    "        attn_mats = []\n",
    "\n",
    "        for t in range(pred_len):\n",
    "            # compute context via attention using current hx as decoder hidden\n",
    "            context, attn_weights = self.attention(enc_outputs, hx)  # context: (B, H_enc) ; attn_weights: (B, T_enc)\n",
    "            lstm_input = torch.cat([prev_out, context], dim=1)  # (B, output_size + H_enc)\n",
    "            hx, cx = self.lstm_cell(lstm_input, (hx, cx))\n",
    "            out = self.fc(self.dropout(hx))  # (B, output_size)\n",
    "            outputs.append(out.unsqueeze(1))\n",
    "            attn_mats.append(attn_weights.unsqueeze(1))  # (B,1,T_enc)\n",
    "\n",
    "            # decide teacher forcing\n",
    "            use_teacher = (y_prev is not None) and (random.random() < teacher_forcing_rate)\n",
    "            if use_teacher:\n",
    "                prev_out = y_prev[:, t, :].to(device)\n",
    "            else:\n",
    "                prev_out = out\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)        # (B, pred_len, output_size)\n",
    "        attn_mats = torch.cat(attn_mats, dim=1)    # (B, pred_len, T_enc)\n",
    "        return outputs, attn_mats\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def forward(self, x, y=None, pred_len=PRED_LEN, teacher_forcing_rate=0.5):\n",
    "        enc_outs, _ = self.encoder(x)\n",
    "        out, att = self.decoder(enc_outs, y_prev=y, pred_len=pred_len, teacher_forcing_rate=teacher_forcing_rate)\n",
    "        return out, att\n",
    "\n",
    "# instantiate model\n",
    "HIDDEN_SIZE = 128\n",
    "enc = Encoder(input_size=OUTPUT_SIZE, hidden_size=HIDDEN_SIZE, n_layers=2, dropout=0.2)\n",
    "dec = Decoder(output_size=OUTPUT_SIZE, hidden_size=HIDDEN_SIZE, enc_hidden_size=HIDDEN_SIZE, dropout=0.2)\n",
    "model = Seq2SeqModel(enc, dec).to(DEVICE)\n",
    "print(\"Model params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# ---------------- 4) Loss, optimizer, scheduler ----------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Removed `verbose` keyword for compatibility with older PyTorch\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "\n",
    "# ---------------- 5) Metrics: MASE, evaluate ----------------\n",
    "def mase(y_true, y_pred, training_series):\n",
    "    \"\"\"\n",
    "    y_true, y_pred: (n_samples, pred_len, n_features) in original scale\n",
    "    training_series: (n_train, n_features) in original scale\n",
    "    Returns scalar (average across features)\n",
    "    \"\"\"\n",
    "    # denom: mean absolute one-step naive forecast error on training data per feature\n",
    "    diffs = np.abs(training_series[1:] - training_series[:-1])  # (n_train-1, n_features)\n",
    "    denom = np.mean(diffs, axis=0)  # (n_features,)\n",
    "    denom = np.where(denom == 0, 1e-8, denom)\n",
    "    mae_per_feature = np.mean(np.abs(y_true - y_pred), axis=(0,1))  # (n_features,)\n",
    "    return float(np.mean(mae_per_feature / denom))\n",
    "\n",
    "def evaluate_model(model, loader, scaler, training_series_scaled):\n",
    "    model.eval()\n",
    "    preds_list, trues_list, atts_list = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            outb, attb = model(xb, y=None, pred_len=PRED_LEN, teacher_forcing_rate=0.0)\n",
    "            preds_list.append(outb.cpu().numpy())\n",
    "            trues_list.append(yb.cpu().numpy())\n",
    "            atts_list.append(attb.cpu().numpy())\n",
    "    preds = np.concatenate(preds_list, axis=0)  # (N, pred_len, F) scaled\n",
    "    trues = np.concatenate(trues_list, axis=0)\n",
    "    atts = np.concatenate(atts_list, axis=0)    # (N, pred_len, enc_T)\n",
    "\n",
    "    # inverse transform\n",
    "    N, T, F = preds.shape\n",
    "    preds_inv = scaler.inverse_transform(preds.reshape(-1, F)).reshape(N, T, F)\n",
    "    trues_inv = scaler.inverse_transform(trues.reshape(-1, F)).reshape(N, T, F)\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(trues_inv.reshape(-1, F), preds_inv.reshape(-1, F)))\n",
    "    mae = mean_absolute_error(trues_inv.reshape(-1, F), preds_inv.reshape(-1, F))\n",
    "    mase_val = mase(trues_inv, preds_inv, scaler.inverse_transform(training_series_scaled))\n",
    "\n",
    "    return {\n",
    "        \"rmse\": float(rmse),\n",
    "        \"mae\": float(mae),\n",
    "        \"mase\": float(mase_val),\n",
    "        \"preds\": preds_inv,\n",
    "        \"trues\": trues_inv,\n",
    "        \"attns\": atts\n",
    "    }\n",
    "\n",
    "# ---------------- 6) Training loop ----------------\n",
    "EPOCHS = 25\n",
    "best_val_metric = float(\"inf\")\n",
    "save_dir = \"outputs_ts_attention_fixed\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outb, _ = model(xb, y=yb, pred_len=PRED_LEN, teacher_forcing_rate=0.5)\n",
    "        loss = criterion(outb, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    mean_train_loss = float(np.mean(losses)) if losses else 0.0\n",
    "\n",
    "    # validation metrics\n",
    "    val_metrics = evaluate_model(model, val_loader, scaler, scaled[:train_end])\n",
    "    val_mae = val_metrics[\"mae\"]\n",
    "    scheduler.step(val_mae)  # step scheduler with monitored metric\n",
    "\n",
    "    print(f\"Epoch {ep}/{EPOCHS}  train_loss={mean_train_loss:.6f}  val_mae={val_mae:.6f}  val_rmse={val_metrics['rmse']:.6f}  val_mase={val_metrics['mase']:.4f}\")\n",
    "\n",
    "    # save best by val_mae\n",
    "    if val_mae < best_val_metric:\n",
    "        best_val_metric = val_mae\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, \"best_model.pth\"))\n",
    "        print(\"Saved best model (val_mae improved).\")\n",
    "\n",
    "# ---------------- 7) Load best and evaluate on test ----------------\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, \"best_model.pth\"), map_location=DEVICE))\n",
    "test_metrics = evaluate_model(model, test_loader, scaler, scaled[:train_end])\n",
    "print(\"TEST metrics:\", test_metrics[\"rmse\"], test_metrics[\"mae\"], test_metrics[\"mase\"])\n",
    "\n",
    "# save metrics & arrays\n",
    "pd.DataFrame([test_metrics[\"rmse\"], test_metrics[\"mae\"], test_metrics[\"mase\"]], index=[\"rmse\",\"mae\",\"mase\"]).to_csv(os.path.join(save_dir, \"test_metrics.csv\"))\n",
    "np.save(os.path.join(save_dir, \"preds.npy\"), test_metrics[\"preds\"])\n",
    "np.save(os.path.join(save_dir, \"trues.npy\"), test_metrics[\"trues\"])\n",
    "\n",
    "# ---------------- 8) Monte Carlo dropout prediction intervals ----------------\n",
    "def mc_dropout_predict(model, x_tensor, scaler, mc_runs=50):\n",
    "    \"\"\"\n",
    "    x_tensor: (1, input_len, features) in scaled units\n",
    "    returns mean, lower, upper in original scale: shapes (pred_len, features)\n",
    "    \"\"\"\n",
    "    # enable dropout during inference\n",
    "    model.train()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(mc_runs):\n",
    "            out, _ = model(x_tensor.to(DEVICE), y=None, pred_len=PRED_LEN, teacher_forcing_rate=0.0)\n",
    "            preds.append(out.cpu().numpy())\n",
    "    preds = np.concatenate(preds, axis=0)  # (mc_runs, 1, pred_len, F) if batch dim preserved or (mc_runs, pred_len, F)\n",
    "    # handle shapes: out above returns (B, pred_len, F); we passed batch 1 likely so preds shape (mc_runs, 1, pred_len, F)\n",
    "    if preds.ndim == 4:\n",
    "        preds = preds[:, 0, :, :]  # (mc_runs, pred_len, F)\n",
    "    mean = preds.mean(axis=0)\n",
    "    lower = np.percentile(preds, 2.5, axis=0)\n",
    "    upper = np.percentile(preds, 97.5, axis=0)\n",
    "    # inverse scale\n",
    "    mean_inv = scaler.inverse_transform(mean.reshape(-1, mean.shape[-1])).reshape(mean.shape)\n",
    "    lower_inv = scaler.inverse_transform(lower.reshape(-1, lower.shape[-1])).reshape(lower.shape)\n",
    "    upper_inv = scaler.inverse_transform(upper.reshape(-1, upper.shape[-1])).reshape(upper.shape)\n",
    "    return mean_inv, lower_inv, upper_inv\n",
    "\n",
    "# Example: MC on first test sample\n",
    "x0, y0 = test_ds[0]\n",
    "mean_pred, lower_pred, upper_pred = mc_dropout_predict(model, x0.unsqueeze(0), scaler, mc_runs=40)\n",
    "\n",
    "# Plot var0 example\n",
    "plt.figure(figsize=(9,3))\n",
    "t = np.arange(PRED_LEN)\n",
    "plt.plot(t, scaler.inverse_transform(y0.numpy())[:,0], label=\"true\")\n",
    "plt.plot(t, mean_pred[:,0], label=\"pred_mean\")\n",
    "plt.fill_between(t, lower_pred[:,0], upper_pred[:,0], alpha=0.3, label=\"95% PI\")\n",
    "plt.legend()\n",
    "plt.title(\"MC Dropout prediction intervals (sample 0, var0)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"mc_dropout_example_var0.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 9) Attention visualizations ----------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xb, yb = next(iter(test_loader))\n",
    "    outb, attb = model(xb.to(DEVICE), y=None, pred_len=PRED_LEN, teacher_forcing_rate=0.0)\n",
    "    att_np = attb.cpu().numpy()  # (B, pred_len, enc_T)\n",
    "\n",
    "# visualize sample 0 attention matrix\n",
    "sample_idx = 0\n",
    "att_sample = att_np[sample_idx]  # (pred_len, enc_T)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(att_sample, aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Encoder time step (input history)\")\n",
    "plt.ylabel(\"Decoder step (prediction horizon)\")\n",
    "plt.title(\"Attention matrix (sample 0)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"attention_matrix_sample0.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# aggregated attention\n",
    "avg_att = att_sample.mean(axis=0)\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(avg_att)\n",
    "plt.title(\"Average attention weight across prediction horizon (sample 0)\")\n",
    "plt.xlabel(\"Encoder time step (older -> recent)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"attention_avg_sample0.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------------- 10) Baseline SARIMAX example (single var) ----------------\n",
    "y = df[\"var0\"].values\n",
    "train_y = y[:train_end]\n",
    "try:\n",
    "    sarima = sm.tsa.SARIMAX(train_y, order=(2,1,2), seasonal_order=(1,0,1,24),\n",
    "                             enforce_stationarity=False, enforce_invertibility=False)\n",
    "    sarima_res = sarima.fit(disp=False)\n",
    "    fc = sarima_res.get_forecast(steps=PRED_LEN)\n",
    "    fc_mean = fc.predicted_mean\n",
    "    print(\"SARIMAX example forecast (first values):\", fc_mean[:5])\n",
    "    with open(os.path.join(save_dir, \"sarima_summary.txt\"), \"w\") as f:\n",
    "        f.write(str(sarima_res.summary()))\n",
    "except Exception as e:\n",
    "    print(\"SARIMAX failed (example). Tweak orders and try again.\", e)\n",
    "\n",
    "print(\"All outputs saved to\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081b67b-f7ef-4578-b46a-37da5504c384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
